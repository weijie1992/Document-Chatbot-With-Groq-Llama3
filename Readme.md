# ðŸ“š RAG Document Q&A with Groq and Llama 3

A simple Retrieval-Augmented Generation (RAG) app built with **Streamlit**, **Groq's Llama 3 (8b)** model, and **FAISS** vector database.

This app allows you to:

- Upload **PDF research papers**,
- Embed and store them into a local FAISS vector database,
- Ask natural language questions,
- Get precise answers sourced **only** from your PDFs â€” **no internet search**!

---

## ðŸš€ Tech Stack

- **[Streamlit](https://streamlit.io/)** â€” UI framework
- **[Groq API](https://groq.com/)** â€” Llama 3-8b LLM
- **[FAISS](https://github.com/facebookresearch/faiss)** â€” Vector database for similarity search
- **[LangChain](https://www.langchain.dev/)** â€” Chains, retrievers, and embeddings
- **OpenAIEmbeddings** â€” For embedding text
- **PyPDFLoader** â€” For loading PDFs
- **Python** 3.9+

---

## ðŸ—ï¸ Project Structure

```bash
.
â”œâ”€â”€ app.py          # Main Streamlit app
â”œâ”€â”€ research_papers/ # (Your local folder with PDFs)
â”œâ”€â”€ .gitignore      # Ignore research_papers and .env
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md       # This file
```

---

## âš™ï¸ Setup Instructions

1. **Clone the repo**

```bash
git clone https://github.com/your-username/rag-document-qa-groq.git
cd rag-document-qa-groq
```

2. **Create a virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Set up environment variables**

Create a `.env` file with the following:

```env
OPENAI_API_KEY=your-openai-api-key
GROQ_API_KEY=your-groq-api-key
```

5. **Prepare your PDFs**

Place your research papers inside the `research_papers/` folder.

6. **Run the app**

```bash
streamlit run app.py
```

---

## âœ¨ Features

- **Document Embedding**: Click the "Document Embedding" button to create a FAISS vector database from your PDFs.
- **Question Answering**: Type any question related to your uploaded PDFs.
- **Context Display**: See which documents were retrieved using Streamlit expanders.
- **Fast Response**: Powered by Groq's ultra-fast Llama 3 API.

---

## ðŸ“‹ Sample Usage

1. Upload PDFs to `/research_papers`
2. Launch the app
3. Click "Document Embedding" to build your vector database
4. Enter a question like:
   > "What is task decomposition in multi-agent systems?"
5. See the answer and the supporting documents!

---

## ðŸ“¦ Requirements

- Python 3.9+
- `streamlit`
- `langchain`
- `langchain-groq`
- `openai`
- `faiss-cpu`
- `python-dotenv`

(Install all via `requirements.txt`)

---
